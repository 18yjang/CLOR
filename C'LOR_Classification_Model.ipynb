{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미 설치된 경우 건너뛰어도 됩니다.\n",
    "!pip install --user seaborn\n",
    "!pip install --user opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습용 코드\n",
    "기존에 학습된 모델을 사용한다면 이 부분은 건너뛰어도 좋습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 준비된 데이터 폴더 경로 설정\n",
    "dir_data = r\"./spao_dataset\"\n",
    "dir_seg = dir_data + \"/seg_gray/\"\n",
    "dir_img = dir_data + \"/img_gray/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리 불러오기\n",
    "import cv2, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False}) #seaborn 자체에 흰색 격자무늬가 생성되기 때문에 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldseg = np.array(os.listdir(dir_seg))\n",
    "fnm = ldseg[10] # 이미지 한개를 선택 (원피스 이미지를 찾기! - 원피스만 seg 클래스가 4개로 인식 됩니다.)\n",
    "print(fnm)\n",
    "\n",
    "#기존 이미지와 주석처리된 이미지 읽기\n",
    "seg = cv2.imread(dir_seg + fnm )\n",
    "img_is = cv2.imread(dir_img + fnm)\n",
    "print(\"seg.shape={}, img_is.shape={}\".format(seg.shape,img_is.shape))\n",
    "\n",
    "\n",
    "# 레이어 읽어서 클래스 분류하기\n",
    "mi, ma = np.min(seg), np.max(seg)\n",
    "n_classes = ma-mi+1\n",
    "print(\"minimum seg = {}, maximum seg = {}, Total number of segmentation classes = {}\".format(mi,ma, n_classes))\n",
    "\n",
    "\n",
    "# 출력\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(img_is)\n",
    "ax.set_title(\"original image\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(seg)\n",
    "ax.set_title(\"annotated image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어 분류 확인하기  (다른 이미지를 확인하려면 윗칸의 2째줄 이미지 변경)\n",
    "plt.hist(img_is.ravel(), 10, [0,10])\n",
    "plt.hist(seg.ravel(), 10, [0,11])\n",
    "\n",
    "fig = plt.figure(figsize=(60,10))\n",
    "for k in range(mi,ma+1):\n",
    "    ax = fig.add_subplot(4,n_classes/4,k+1)\n",
    "    ax.imshow((seg == k)*1.0)\n",
    "    ax.set_title(\"label = {}\".format(k))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FCN은 이미지의 크기를 조정할 필요는 없지만, 정확도를 위해 기존 모델을 학습하는 동안은 데이터의 크기를 동일하게 조정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def give_color_to_seg_img(seg,n_classes):    # 각 클래스에 색상 입히기\n",
    "    '''\n",
    "    seg : (input_width,input_height,3)\n",
    "    '''\n",
    "    \n",
    "    if len(seg.shape)==3:\n",
    "        seg = seg[:,:,0]\n",
    "    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n",
    "    colors = sns.color_palette(\"hls\", n_classes)\n",
    "    \n",
    "    for c in range(n_classes):\n",
    "        segc = (seg == c)\n",
    "        seg_img[:,:,0] += (segc*( colors[c][0] ))\n",
    "        seg_img[:,:,1] += (segc*( colors[c][1] ))\n",
    "        seg_img[:,:,2] += (segc*( colors[c][2] ))\n",
    "\n",
    "    return(seg_img)\n",
    "\n",
    "input_height , input_width = 224 , 224\n",
    "output_height , output_width = 224 , 224\n",
    "\n",
    "\n",
    "ldseg = np.array(os.listdir(dir_seg))\n",
    "for fnm in ldseg[np.random.choice(len(ldseg),3,replace=False)]:\n",
    "    fnm = fnm.split(\".\")[0]\n",
    "    seg = cv2.imread(dir_seg + fnm + \".png\")\n",
    "    img_is = cv2.imread(dir_img + fnm + \".png\")\n",
    "    seg_img = give_color_to_seg_img(seg,n_classes)\n",
    "\n",
    "    fig = plt.figure(figsize=(20,40)) \n",
    "    ax = fig.add_subplot(1,4,1)\n",
    "    ax.imshow(seg_img)\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,2)\n",
    "    ax.imshow(img_is/255.0)\n",
    "    ax.set_title(\"original image {}\".format(img_is.shape[:2]))\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,3)\n",
    "    ax.imshow(cv2.resize(seg_img,(input_height , input_width)))\n",
    "    \n",
    "    ax = fig.add_subplot(1,4,4)\n",
    "    ax.imshow(cv2.resize(img_is,(output_height , output_width))/255.0)\n",
    "    ax.set_title(\"resized to {}\".format((output_height , output_width)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 배열 불러들이는 메서드\n",
    "def getImageArr( path , width , height ):\n",
    "        img = cv2.imread(path, 1)\n",
    "        img = np.float32(cv2.resize(img, ( width , height ))) / 127.5 - 1   #이미지 크기 조정\n",
    "        return img\n",
    "\n",
    "def getSegmentationArr( path , nClasses ,  width , height  ):\n",
    "\n",
    "    seg_labels = np.zeros((  height , width  , nClasses ))\n",
    "    img = cv2.imread(path, 1)\n",
    "    img = cv2.resize(img, ( width , height ))    # 이미지 크기 조정\n",
    "    img = img[:, : , 0]\n",
    "\n",
    "    for c in range(nClasses):\n",
    "        seg_labels[: , : , c ] = (img == c ).astype(int)\n",
    "    ##seg_labels = np.reshape(seg_labels, ( width*height,nClasses  ))\n",
    "    return seg_labels\n",
    "\n",
    "images = os.listdir(dir_img)\n",
    "images.sort()\n",
    "segmentations  = os.listdir(dir_seg)\n",
    "segmentations.sort()\n",
    "    \n",
    "X = []\n",
    "Y = []\n",
    "for im , seg in zip(images,segmentations) :    # 이미지 불러들이는 과정에서 오류 확인\n",
    "    try:\n",
    "        X.append( getImageArr(dir_img + im , 224 , 224 )  ) # 224 = input_width, input_height (으로 변경해도 됨)\n",
    "        Y.append( getSegmentationArr( dir_seg + seg , n_classes , 224 , 224 )  ) # 224 = output_width, output_height\n",
    "    except cv2.error as e:\n",
    "        print(im);\n",
    "        \n",
    "X, Y = np.array(X) , np.array(Y)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 세트 섞기, 학습/테스트 셋 분류하기\n",
    "from sklearn.utils import shuffle\n",
    "train_rate = 0.65\n",
    "index_train = np.random.choice(X.shape[0],int(X.shape[0]*train_rate),replace=False)\n",
    "index_test  = list(set(range(X.shape[0])) - set(index_train))\n",
    "\n",
    "    \n",
    "X, Y = shuffle(X,Y)\n",
    "X_train, Y_train = X[index_train],Y[index_train]\n",
    "X_test, Y_test = X[index_test],Y[index_test]\n",
    "\n",
    "#train dataset 확인하기\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(X_train[9])\n",
    "ax.set_title(\"train image\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.imshow(X_test[9])\n",
    "ax.set_title(\"test image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 가동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델에 필요한 라이브러리 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.backend import set_session\n",
    "import keras, sys, time, warnings\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import pandas as pd \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "config.gpu_options.visible_device_list = \"2\" \n",
    "\n",
    "print(\"python {}\".format(sys.version))\n",
    "print(\"keras version {}\".format(keras.__version__)); del keras\n",
    "print(\"tensorflow version {}\".format(tf.__version__))   #버전 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 학습된 모델 불러오기 (신규 모델 학습시 제거)\n",
    "## 모델 다운로드 주소 : https://drive.google.com/file/d/1u9sruBWJ46Jr1_rpWLk0eiA1ce2DHmm-/view?usp=sharing\n",
    "VGG_Weights_path = \"./my_h5_model_0609.h5\"   # my_h5_model_0609.h5 파일 위치 수정하기 / 새로 학습된 모델 저장시 명칭 변경하기\n",
    "model = load_model(VGG_Weights_path)    ## VGG_Weights_path = Prev_Model_path (추후 변수 명칭 수정 예정)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신규 모델 생성\n",
    "def FCN8( nClasses ,  input_height=224, input_width=224):\n",
    "    assert input_height%32 == 0\n",
    "    assert input_width%32 == 0\n",
    "    IMAGE_ORDERING =  \"channels_last\" \n",
    "\n",
    "    img_input = Input(shape=(input_height,input_width, 3))\n",
    "    \n",
    "    ## Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', data_format=IMAGE_ORDERING )(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f1 = x\n",
    "    \n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    f2 = x\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool', data_format=IMAGE_ORDERING )(x)\n",
    "    pool3 = x\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    pool4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool', data_format=IMAGE_ORDERING )(x)## (None, 14, 14, 512) \n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', data_format=IMAGE_ORDERING )(pool4)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', data_format=IMAGE_ORDERING )(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', data_format=IMAGE_ORDERING )(x)\n",
    "    pool5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool', data_format=IMAGE_ORDERING )(x)## (None, 7, 7, 512)\n",
    "\n",
    "\n",
    "    vgg  = Model(  img_input , pool5  )\n",
    "    \n",
    "    n = 4096\n",
    "    o = ( Conv2D( n , ( 7 , 7 ) , activation='relu' , padding='same', name=\"conv6\", data_format=IMAGE_ORDERING))(pool5)\n",
    "    conv7 = ( Conv2D( n , ( 1 , 1 ) , activation='relu' , padding='same', name=\"conv7\", data_format=IMAGE_ORDERING))(o)\n",
    "    \n",
    "    \n",
    "    ## 4배 upsamping (pool4 layer)\n",
    "    conv7_4 = Conv2DTranspose( nClasses , kernel_size=(4,4) ,  strides=(4,4) , use_bias=False, data_format=IMAGE_ORDERING )(conv7)\n",
    "    ## (None, 224, 224, 10)\n",
    "    ## 2배 upsampling(pool411)\n",
    "    pool411 = ( Conv2D( nClasses , ( 1 , 1 ) , activation='relu' , padding='same', name=\"pool4_11\", data_format=IMAGE_ORDERING))(pool4)\n",
    "    pool411_2 = (Conv2DTranspose( nClasses , kernel_size=(2,2) ,  strides=(2,2) , use_bias=False, data_format=IMAGE_ORDERING ))(pool411)\n",
    "    \n",
    "    pool311 = ( Conv2D( nClasses , ( 1 , 1 ) , activation='relu' , padding='same', name=\"pool3_11\", data_format=IMAGE_ORDERING))(pool3)\n",
    "        \n",
    "    o = Add(name=\"add\")([pool411_2, pool311, conv7_4 ])\n",
    "    o = Conv2DTranspose( nClasses , kernel_size=(8,8) ,  strides=(8,8) , use_bias=False, data_format=IMAGE_ORDERING )(o)\n",
    "    o = (Activation('softmax'))(o)\n",
    "    \n",
    "    model = Model(img_input, o)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = FCN8(nClasses     = n_classes,  \n",
    "             input_height = 224, \n",
    "             input_width  = 224)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "\n",
    "sgd = optimizers.SGD(lr=1E-2, decay=5**(-4), momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "hist1 = model.fit(X_train,Y_train,\n",
    "                  validation_data=(X_test,Y_test),\n",
    "                  batch_size=32,epochs=50, verbose=2)  # epoch 변경하여 횟수 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in ['loss', 'val_loss']:\n",
    "    plt.plot(hist1.history[key],label=key)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_predi = np.argmax(y_pred, axis=3)\n",
    "y_testi = np.argmax(Y_test, axis=3)\n",
    "print(y_testi.shape,y_predi.shape)\n",
    "\n",
    "# 아직 수정중인 부분(추출된 부분에 대한 classification 출력하기 위함)\n",
    "#predictions = model.predict(X_test)\n",
    "#class_names = ['Bottom', 'Top', 'One-piece']\n",
    "\n",
    "#class_names[np.argmax(predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(Yi,y_predi):\n",
    "    ## mean Intersection over Union\n",
    "    ## Mean IoU = TP/(FN + TP + FP)\n",
    "\n",
    "    IoUs = []\n",
    "    Nclass = int(np.max(Yi)) + 1\n",
    "    for c in range(Nclass):\n",
    "        TP = np.sum( (Yi == c)&(y_predi==c) )\n",
    "        FP = np.sum( (Yi != c)&(y_predi==c) )\n",
    "        FN = np.sum( (Yi == c)&(y_predi != c)) \n",
    "        IoU = TP/float(TP + FP + FN)\n",
    "        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
    "        IoUs.append(IoU)\n",
    "    mIoU = np.mean(IoUs)\n",
    "    print(\"_________________\")\n",
    "    print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
    "    \n",
    "IoU(y_testi,y_predi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(40): # 숫자 조정하여 출력 개수 조정\n",
    "    img_is  = (X_test[i] + 1)*(255.0/2)\n",
    "    seg = y_predi[i]\n",
    "    segtest = y_testi[i]\n",
    "\n",
    "    fig = plt.figure(figsize=(10,30))    \n",
    "    ax = fig.add_subplot(1,3,1)\n",
    "    ax.imshow(img_is/255.0)\n",
    "    ax.set_title(\"original\")\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,2)\n",
    "    ax.imshow(seg)\n",
    "    ax.imshow(give_color_to_seg_img(seg,n_classes))\n",
    "    ax.set_title(\"predicted class\")\n",
    "    plt.imsave('./spao_dataset/pred/pred_'+str(i)+'.png', seg)\n",
    "    \n",
    "    ax = fig.add_subplot(1,3,3)\n",
    "    ax.imshow(segtest)\n",
    "    ax.imshow(give_color_to_seg_img(segtest,n_classes))\n",
    "    ax.set_title(\"true class\")\n",
    "\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 학습모델 저장\n",
    "model.save(\"my_h5_model_0611.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
